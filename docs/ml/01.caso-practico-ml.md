# Caso Práctico: TalentForecast Pro - Sistema de Predicción para el Mercado Laboral

## Hiring Time Forecast + Salary Benchmark

---

**Documento de Requerimientos del Cliente**  
**Fecha:** Enero 2026  
**Proyecto:** TalentForecast Pro  
**Tecnología Principal:** Python 3.11+ con FastAPI, LightGBM, CatBoost, MLflow  
**Metodología:** Spec-Driven Development Híbrido (SDD + ML) con GitHub Copilot  
**Duración Total:** 12 horas (4 módulos prácticos)

---

## 1. Introducción y Contexto del Proyecto

### 1.1 Acerca de TalentHub Solutions

TalentHub Solutions es una empresa especializada en soluciones tecnológicas para recursos humanos. La compañía ha desarrollado exitosamente un Portal de Empleo que conecta empresas reclutadoras con profesionales en búsqueda de nuevas oportunidades laborales. Este portal genera diariamente datos valiosos sobre el mercado laboral: ofertas publicadas, postulaciones recibidas, salarios declarados, y resultados de procesos de contratación.

Sin embargo, la empresa ha identificado una oportunidad crítica de mejora: esta valiosa información no se está aprovechando para generar inteligencia que beneficie tanto a empresas como a candidatos. Las empresas publican ofertas sin tener contexto sobre cuánto tiempo tardarán en encontrar el candidato adecuado o cuál es el rango salarial competitivo para cada tipo de puesto.

El equipo técnico de TalentHub Solutions ha decidido desarrollar un sistema de predicción avanzado que aproveche estos datos históricos para generar insights accionables. La convicción del equipo es que las metodologías de desarrollo asistido por inteligencia artificial, específicamente mediante el uso de herramientas como Microsoft Copilot y el enfoque Spec-Driven Development adaptado para proyectos experimentales de machine learning, permitirán mejorar la productividad manteniendo la calidad y acelerando significativamente el time-to-market de este proyecto.

Este caso práctico sigue el enfoque SDD-AGENTS-SKILLS definido en el curso, complementado con extensiones específicas para proyectos de machine learning y data science. Los comandos Spec Kit se complementan con patrones de experimentación controlada, gates de decisión basados en métricas, y tracking sistemático con MLflow.

### 1.2 Visión Global del Producto

TalentForecast Pro será un sistema completo de predicción para el mercado laboral que constará de cuatro componentes principales trabajando de forma coordinada.

El primer componente es el **Pipeline de Ingesta de Datos** que consumirá datos del Portal de Empleo existente mediante APIs REST. Este componente utilizará httpx para consumo asíncrono de datos, schedule para orquestación dejobs programados, y validación de calidad con Great Expectations en cada ejecución.

El segundo componente es el **Sistema de Feature Engineering** que transformará los datos crudos en features listas para modelado. Este sistema implementará embeddings de skills mediante TF-IDF y técnicas de reducción de dimensionalidad, características de empresa basadas en historial de contrataciones, y métricas de condiciones de mercado como índice de escasez de skills y tasa de demanda.

El tercer componente es el **Motor de Predicción ML** que entrenará y servirá modelos de machine learning. El modelo de Hiring Time Forecast utilizará LightGBM con Optuna para hyperparameter tuning, buscando predecir días hasta contratación con MAE menor a 5 días. El modelo de Salary Benchmark utilizará CatBoost para estimar rangos salariales competitivos con MAPE menor al 10%.

El cuarto componente es la **API de Predicción y Dashboard** que proporcionará acceso a las predicciones. FastAPI servirá endpoints REST para predicciones en tiempo real, mientras que Streamlit proveerá dashboards interactivos con análisis de tendencias del mercado laboral.

Durante esta etapa del curso, el equipo se centrará en el desarrollo del pipeline de datos, feature engineering, modelos de predicción, y la API de servicio. Los dashboards y la integración completa con el Portal de Empleo se completarán en fases posteriores.

### 1.3 Objetivo del Caso Práctico

El objetivo de este caso práctico es que el equipo de desarrollo construya el sistema TalentForecast Pro utilizando metodologías de Spec-Driven Development híbridas, asistidas por Microsoft Copilot, con un enfoque especial en la experimentación controlada y reproducible en proyectos de machine learning.

Al finalizar los cuatro módulos del curso, deberán tener un sistema funcional que implemente predicciones precisas de tiempo de contratación y benchmarks salariales, siguiendo las mejores prácticas de MLOps, experimentación reproducible, y los estándares establecidos por la industria para proyectos data.

---

## 2. Requisitos Funcionales del Sistema

### 2.1 Módulo de Predicción de Tiempo de Contratación

Este módulo es el componente central del sistema y proporcionará predicciones precisas sobre cuántos días tardará una empresa en cubrir una vacancy específica.

**RF-001: Predicción de Días hasta Contratación**

El sistema debe proporcionar un endpoint POST en /forecast/hiring-time que reciba las características de una oferta de empleo y retorne una predicción del número de días hasta contratación. Los datos de entrada incluirán título del puesto, descripción, skills requeridas, ubicación, tipo de contrato, nivel de experiencia requerido, industria, y tamaño de la empresa. La respuesta incluirá prediction_days como valor central, confidence_interval con rango del 80%, y top_influential_features con las features que más impactan la predicción.

**RF-002: Features de Entrada para Predicción**

El sistema debe aceptar las siguientes categorías de features para cada predicción: job_features incluyendo título encodeado, años experiencia requeridos, tipo de contrato, y nivel del puesto; company_features incluyendo tamaño de empresa, industria, y velocidad histórica de contratación; market_features incluyendo índice de escasez de skills para las requeridas, tasa de demanda del mercado, y salario promedio del mercado para posiciones similares; y location_features incluyendo ciudad, modalidad remoto/híbrido, y tier de la ubicación.

**RF-003: Interpretabilidad de Predicciones**

El sistema debe proporcionar explicabilidad para cada predicción mediante SHAP values. Para cada predicción, el sistema retornará feature_importance mostrando el impacto de cada feature en la predicción, direction mostrando si cada feature aumenta o disminuye el tiempo esperado, y comparison comparando con ofertas similares en el histórico.

### 2.2 Módulo de Salary Benchmark

Este módulo proporcionará rangos salariales competitivos basados en tendencias del portal y datos históricos.

**RF-004: Estimación de Rango Salarial**

El sistema debe proporcionar un endpoint POST en /benchmark/salary que reciba las características de una oferta y retorne un rango salarial competitivo. Los datos de entrada incluirán título del puesto, nivel de experiencia, ubicación, tipo de contrato, industria, y skills requeridas. La respuesta incluirá salary_range con valores min, mid, y max, percentile indicando en qué percentil se encuentra el rango propuesto, market_comparison comparando con el promedio del mercado, y adjustment_recommendations sugiriendo ajustes si el rango propuesto está fuera de mercado.

**RF-005: Análisis de Competitividad Salarial**

El sistema debe permitir evaluar si un salario propuesto es competitivo mediante un endpoint POST en /benchmark/competitiveness. Este endpoint recibirá salary_proposed, job_features, y location, y retornará competitiveness_score de 0 a 100, market_position indicando si está por encima, en línea, o por debajo del mercado, y recommendations para ajustes.

**RF-006: Actualización de Datos Salariales**

El sistema debe mantener los datos salariales actualizados mediante un proceso de ingesta que consuma salarios declarados en ofertas históricas y resultados de procesos de contratación exitosos. Los datos se actualizarán semanalmente para mantener relevancia.

### 2.3 Módulo de Analytics y Dashboard

Este módulo proporcionará insights agregados sobre tendencias del mercado laboral.

**RF-007: Dashboard de Tendencias**

El sistema debe proporcionar un dashboard Streamlit que muestre market_overview con estadísticas agregadas del mercado laboral, skill_demand_ranking con las skills más demandadas y su evolución temporal, salary_trends mostrando la evolución de salarios por industria y nivel de experiencia, hiring_velocity comparando tiempos de contratación por industria y tamaño de empresa, y market_insights con alertas sobre skills emergentes y cambios de tendencia.

**RF-008: Endpoints de Analytics**

El sistema debe proporcionar endpoints REST para acceso programático a analytics: GET /analytics/trends retornará tendencias del mercado laboral en formato JSON, GET /analytics/skills-demand retornará ranking de skills más demandadas con métricas, y GET /analytics/salary-distribution retornará distribución salarial por categoría de puesto.

**RF-009: Alertas de Mercado**

El sistema debe generar alertas automáticas cuando se detecten cambios significativos en el mercado: emerging_skills notificando skills con crecimiento acelerado en demanda, salary_shifts alertando sobre cambios significativos en rangos salariales por categoría, y demand_spikes detectando picos de demanda inusuales en categorías específicas.

### 2.4 Módulo de Feature Store

Este módulo gestionará el almacenamiento y versionado de features para entrenamiento y scoring.

**RF-010: Ingesta de Features**

El sistema debe consumir datos del Portal de Empleo API mediante un pipeline programado que extraiga Job Offers con datos completos, Applications con timestamps y estados, y Hiring Outcomes con resultados de procesos completados. La ingesta validará calidad de datos con Great Expectations y almacenará en Feature Store versionado.

**RF-011: Feature Store**

El sistema implementará un Feature Store que permita storage de features con versionado temporal, retrieval de features para entrenamiento de modelos, retrieval de features para scoring en tiempo real, y lineage desde datos crudos hasta features consumidas por modelos.

---

## 3. Requisitos No Funcionales

### 3.1 Rendimiento de Modelos

**RNF-001: Métricas de Hiring Time Model**

El modelo de predicción de tiempo de contratación debe cumplir los siguientes criterios de éxito: Mean Absolute Error menor a 5 días para ofertas con historial mayor a 30 días, R² mayor a 0.70 en validación con TimeSeriesSplit, latencia de predicción menor a 100ms en P99, y coverage de feature importance interpretable con SHAP.

**RNF-002: Métricas de Salary Benchmark Model**

El modelo de salary benchmark debe cumplir: Mean Absolute Percentage Error menor al 10% para ofertas con salary declarado, coverage del 80% con intervalos de confianza del 90%, explicabilidad por feature mediante SHAP, y detección de outliers salariales con precisión mayor al 85%.

**RNF-003: Objetivos de Rendimiento de Sistema**

El sistema completo debe cumplir: disponibilidad del 99.5%, tiempo de respuesta de API menor a 200ms en P95 para endpoints de predicción, capacidad de 1000 predicciones por minuto, y retención de datos de entrenamiento por 24 meses.

### 3.2 Arquitectura de Datos

**RNF-004: Estructura del Proyecto**

El proyecto seguirá esta estructura de directorios para mantener organización y reproducibilidad:

```
talent-forecast-pro/
├── .specify/
│   └── memory/
│       └── constitution.md          # Principios del proyecto ML
├── specs/
│   ├── 001-data-ingestion/
│   │   ├── spec.md                  # Criterios de ingesta
│   │   ├── plan.md                  # Arquitectura de ingesta
│   │   └── tasks.md                 # Tareas de implementación
│   ├── 002-feature-engineering/
│   │   ├── spec.md                  # Features requeridas
│   │   ├── plan.md                  # Transformaciones
│   │   └── tasks.md
│   ├── 003-hiring-time-model/
│   │   ├── spec.md                  # Hipótesis experimentales
│   │   ├── plan.md                  # Plan de experimentación
│   │   └── tasks.md
│   ├── 004-salary-benchmark-model/
│   │   ├── spec.md                  # Hipótesis experimentales
│   │   ├── plan.md                  # Plan de experimentación
│   │   └── tasks.md
│   ├── 005-prediction-api/
│   │   ├── spec.md                  # API specs
│   │   ├── plan.md
│   │   └── tasks.md
│   └── 006-dashboard/
│       ├── spec.md
│       └── plan.md
├── experiments/
│   ├── hiring-time/
│   │   ├── 01_baseline_linear.ipynb
│   │   ├── 02_xgboost_basic.ipynb
│   │   ├── 03_lightgbm_tuning.ipynb
│   │   └── 04_final_model.ipynb
│   └── salary/
│       ├── 01_exploratory_analysis.ipynb
│       ├── 02_catboost_baseline.ipynb
│       └── 03_hyperparameter_tuning.ipynb
├── mlruns/                          # MLflow tracking
├── src/
│   ├── data_ingestion/
│   │   ├── portal_client.py         # Cliente httpx para Portal API
│   │   ├── ingest_pipeline.py       # Pipeline de ingesta
│   │   └── validators.py            # Great Expectations
│   ├── features/
│   │   ├── skills_embeddings.py     # TF-IDF + PCA/UMAP
│   │   ├── company_features.py      # Features de empresa
│   │   └── market_features.py       # Features de mercado
│   ├── models/
│   │   ├── hiring_time/
│   │   │   ├── train.py             # Entrenamiento LightGBM
│   │   │   ├── predict.py           # Scoring
│   │   │   └── explain.py           # SHAP explainer
│   │   └── salary_benchmark/
│   │       ├── train.py             # Entrenamiento CatBoost
│   │       ├── predict.py           # Scoring
│   │       └── explain.py           # SHAP explainer
│   ├── api/
│   │   ├── main.py                  # FastAPI app
│   │   ├── routes/
│   │   │   ├── forecast.py          # Endpoints de predicción
│   │   │   ├── benchmark.py         # Endpoints de salary
│   │   │   └── analytics.py         # Endpoints de analytics
│   │   └── schemas/
│   │       ├── request.py           # Pydantic schemas request
│   │       └── response.py          # Pydantic schemas response
│   ├── dashboard/
│   │   └── app.py                   # Streamlit dashboard
│   └── monitoring/
│       ├── drift_detection.py       # Monitor de drift
│       └── alerts.py                # Sistema de alertas
├── tests/
│   ├── unit/
│   ├── integration/
│   └── performance/
├── data/
│   ├── raw/                         # Datos crudos del Portal API
│   ├── processed/                   # Features procesadas
│   └── models/                      # Modelos guardados
├── docs/
├── requirements.txt
├── Dockerfile
└── README.md
```

**RNF-005: Patrones de Diseño ML**

La implementación debe utilizar los siguientes patrones para proyectos data:

Feature Engineering Pipeline pattern con transformacioneschainables y logging de cada paso, Experiment Tracking con MLflow incluyendo parámetros, métricas, y artefactos, Model Registry para versionado de modelos con staging (staging/production), y Feature Store con versionado temporal y lineage.

### 3.3 Estándares de Código

**RNF-006: Convenciones de Nomenclatura Python**

El código seguirá las siguientes convenciones de nomenclatura:

| Elemento | Convención | Ejemplo |
|----------|------------|---------|
| Clases | PascalCase | HiringTimePredictor |
| Funciones | snake_case | calculate_feature_importance |
| Variables | snake_case | feature_store |
| Constantes | UPPER_SCASE | MAX_PREDICTION_DAYS |
| Archivos | snake_case | feature_engineering.py |
| Tests | test_*.py | test_hiring_time_model.py |
| Notebooks | NN_*.ipynb | 01_baseline_linear.ipynb |

**RNF-007: Documentación de Código**

Toda función pública, clase de modelo, y pipeline debe incluir docstrings en formato Google:

```python
def train_hiring_time_model(X_train, y_train, params):
    """
    Entrena el modelo de predicción de tiempo de contratación.
    
    Args:
        X_train: DataFrame con features de entrenamiento
        y_train: Serie con variable objetivo (días hasta contratación)
        params: Diccionario con hiperparámetros de LightGBM
    
    Returns:
        model: Modelo entrenado
        metrics: Diccionario con métricas de entrenamiento
    
    Raises:
        ValueError: Si los datos no cumplen requisitos de validación
    """
```

### 3.4 MLOps y Reproducibilidad

**RNF-008: MLflow Tracking**

Todo experimento debe registrar en MLflow: parámetros completos del modelo y preprocesamiento, métricas de entrenamiento y validación, artifact paths incluyendo datasets, modelos, y shap values, environment con dependencias exactas, y git commit hash para trazabilidad.

**RNF-009: Reproducibilidad**

El sistema debe garantizar reproducibilidad mediante fixed random seeds en todos los componentes aleatorios, versionado de dependencias en requirements.txt, versionado de datos en Feature Store, y containerización con Docker para producción.

**RNF-010: Drift Detection**

El sistema debe monitorear drift en producción: data drift detectando cambios en distribución de features, model drift detectando degradación en métricas de predicción, y alerts notificando cuando drift exceda thresholds definidos.

### 3.5 Seguridad

**RNF-011: Acceso a Datos**

El sistema consumirá datos del Portal de Empleo API utilizando las credenciales del sistema con autenticación JWT, acceso mínimo necesario según principio de least privilege, logging de todos los accesos a datos sensibles, y rate limiting para proteger el Portal API.

**RNF-012: API Security**

La API de predicción implementará autenticación mediante API key para clientes externos, rate limiting por cliente, validación de inputs para prevenir injection attacks, y logging de todas las predicciones con propósitos de auditoría.

---

## 4. Arquitectura del Sistema

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    TALENTFORECAST PRO - ARQUITECTURA                        │
└─────────────────────────────────────────────────────────────────────────────┘

                              ┌─────────────────┐
                              │   CLIENTES      │
                              │                 │
                              │  • Web Dashboard│
                              │  • API Clients  │
                              │  • Portal API   │
                              └────────┬────────┘
                                       │
                                       │ HTTPS (REST + API Keys)
                                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                          API LAYER (FastAPI)                                │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │                      ENDPOINTS                                      │    │
│  │  ┌──────────────────┐ ┌────────────────┐ ┌──────────────────────┐   │    │
│  │  │ POST /forecast/  │ │ POST /benchmark│ │ GET /analytics/      │   │    │
│  │  │   hiring-time    │ │    /salary     │ │   trends             │   │    │
│  │  │                  │ │                │ │                      │   │    │
│  │  │ • Input schema   │ │ • Input schema │ │ • Skills demand      │   │    │
│  │  │ • SHAP values    │ │ • Range output │ │ • Salary trends      │   │    │
│  │  │ • Confidence int │ │ • Market comp  │ │ • Insights           │   │    │
│  │  └──────────────────┘ └────────────────┘ └──────────────────────┘   │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│                              │                                              │
│                              ▼                                              │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                   MIDDLEWARE                                         │   │
│  │  ┌────────────────┐ ┌───────────────┐ ┌────────────────────────┐     │   │
│  │  │ Authentication │ │   Rate Limit  │ │   Request Logging      │     │   │
│  │  │                │ │               │ │                        │     │   │
│  │  │ • API Key      │ │ • Per client  │ │ • Correlation ID       │     │   │
│  │  │ • JWT reuse    │ │ • Quota       │ │ • Prediction log       │     │   │
│  │  └────────────────┘ └───────────────┘ └────────────────────────┘     │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                       MODEL SERVING LAYER                                   │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                    PREDICTION SERVICE                                │   │
│  │                                                                      │   │
│  │  ┌────────────────────────────┐  ┌────────────────────────────┐      │   │
│  │  │    Hiring Time Model       │  │    Salary Benchmark Model  │      │   │
│  │  │                            │  │                            │      │   │
│  │  │  • LightGBM Regressor      │  │  • CatBoost Regressor      │      │   │
│  │  │  • MAE < 5 días            │  │  • MAPE < 10%              │      │   │
│  │  │  • SHAP explainer          │  │  • SHAP explainer          │      │   │
│  │  │  • Latency < 100ms         │  │  • Confidence intervals    │      │   │
│  │  └────────────────────────────┘  └────────────────────────────┘      │   │
│  │                                                                      │   │
│  │  ┌──────────────────────────────────────────────────────────────┐    │   │
│  │  │              FEATURE ENGINEERING PIPELINE                    │    │   │
│  │  │                                                              │    │   │
│  │  │  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌──────────┐   │    │   │
│  │  │  │ Skills     │ │ Company    │ │ Market     │ │ Location │   │    │   │
│  │  │  │ Embeddings │ │ Features   │ │ Conditions │ │ Features │   │    │   │
│  │  │  │            │ │            │ │            │ │          │   │    │   │
│  │  │  │ • TF-IDF   │ │ • Size     │ │ • Demand   │ │ • City   │   │    │   │
│  │  │  │ • PCA/UMAP │ │ • Industry │ │ • Scarcity │ │ • Remote │   │    │   │
│  │  │  │ • Count    │ │ • History  │ │ • Avg Sal  │ │ • Tier   │   │    │   │
│  │  │  └────────────┘ └────────────┘ └────────────┘ └──────────┘   │    │   │
│  │  └──────────────────────────────────────────────────────────────┘    │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                       DATA LAYER                                            │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │                    FEATURE STORE (Feast/Delta)                      │    │
│  │                                                                     │    │
│  │  ┌─────────────────┐ ┌─────────────────┐ ┌───────────────────────┐  │    │
│  │  │ Job Features    │ │ Company Features│ │ Market Features       │  │    │
│  │  │                 │ │                 │ │                       │  │    │
│  │  │ • title_emb     │ │ • size          │ │ • skill_demand_rate   │  │    │
│  │  │ • skills_list   │ │ • industry      │ │ • skill_scarcity_idx  │  │    │
│  │  │ • experience    │ │ • hiring_vel    │ │ • avg_salary_by_cat   │  │    │
│  │  │ • contract_type │ │ • avg_time_to   │ │ • market_growth       │  │    │
│  │  │ • location      │ │   hire          │ │                       │  │    │
│  │  └─────────────────┘ └─────────────────┘ └───────────────────────┘  │    │
│  │                                                                     │    │
│  │  ┌───────────────────────────────────────────────────────────────┐  │    │
│  │  │                     MLFLOW REGISTRY                           │  │    │
│  │  │                                                               │  │    │
│  │  │  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐  │  │    │
│  │  │  │ Hiring Time     │ │ Salary Benchmark│ │ Experiments     │  │  │    │
│  │  │  │ Models          │ │ Models          │ │ Tracking        │  │  │    │
│  │  │  │                 │ │                 │ │                 │  │  │    │
│  │  │  │ • Staging       │ │ • Staging       │ │ • Parameters    │  │  │    │
│  │  │  │ • Production    │ │ • Production    │ │ • Metrics       │  │  │    │
│  │  │  │ • Archived      │ │ • Archived      │ │ • Artifacts     │  │  │    │
│  │  │  └─────────────────┘ └─────────────────┘ └─────────────────┘  │  │    │
│  │  └───────────────────────────────────────────────────────────────┘  │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                     EXTERNAL INTEGRATION                                    │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────────────────┐  │
│  │  Portal API     │  │    MLflow       │  │   Great Expectations        │  │
│  │  (Source Data)  │  │  (Tracking)     │  │   (Data Quality)            │  │
│  │                 │  │                 │  │                             │  │
│  │  • Job Offers   │  │  • Experiments  │  │  • Data validation          │  │
│  │  • Applications │  │  • Models       │  │  • Expectations suites      │  │
│  │  • Hiring Out.  │  │  • Registry     │  │  • Data profiling           │  │
│  └─────────────────┘  └─────────────────┘  └─────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 5. Enfoque SDD Híbrido para Proyectos ML

### 5.1 El Desafío: SDD vs. Experimentación

Los proyectos de machine learning tienen una naturaleza inherentemente exploratoria donde no se sabe de antemano qué modelo funcionará mejor, qué features serán más importantes, o cuáles serán los hiperparámetros óptimos. El SDD tradicional parte de specs definidas al inicio, lo cual resulta incompatible con la realidad de los proyectos data.

La solución es un **SDD Híbrido** que combina la disciplina del Spec-Driven Development con flexibilidad para experimentación controlada. Este enfoque mantiene la trazabilidad y estructura del SDD mientras permite la iteración necesaria en proyectos de machine learning.

### 5.2 Fases del SDD Híbrido para ML

| Fase | SDD Tradicional | SDD Híbrido para ML |
|------|-----------------|---------------------|
| **Spec** | Solución definida | Hipótesis a validar |
| **Plan** | Implementación directa | Plan de experimentación |
| **Tareas** | Lineales | Con gates de decisión |
| **Implementación** | Una vez | Iterativa con checkpoints |
| **Validación** | Contra specs | Contra métricas + gates |

### 5.3 Principios Clave del SDD Híbrido

**Principio 1: Spec de Hipótesis**

En lugar de definir la solución exacta, las specs definen qué se quiere lograr y qué hipótesis se van a validar. Ejemplo: "El modelo LightGBM con features de mercado supera al baseline lineal por más del 20% en MAE".

**Principio 2: Gates de Decisión**

Entre cada fase experimental hay puntos de control donde se decide si continuar con la fase actual, hacer fallback a una fase anterior, o cambiar de enfoque. Los gates se basan en métricas objetivas, no en intuición.

**Principio 3: Baseline Obligatorio**

Antes de entrenar modelos complejos, se establece un baseline de referencia. Solo tiene sentido optimizar si se supera el baseline por un margen significativo.

**Principio 4: MLflow como SDD Tracker**

Todo el proceso experimental queda documentado en MLflow, funcionando como tracker del SDD. Los artefactos, métricas, y decisiones quedan registrados con trazabilidad completa.

**Principio 5: Spec Final**

Solo cuando el modelo cumple criterios objetivos se crea la especificación final del modelo. Esto freezea la solución que pasó todos los gates.

### 5.4 Artefactos SDD por Fase

| Fase | Comando Spec Kit | Artefacto | Descripción |
|------|------------------|-----------|-------------|
| 0 | `/speckit.constitution` | `.specify/memory/constitution.md` | Principios SDD + ML |
| 1 | `/speckit.specify` | `specs/00*-*/spec.md` | 6 specs con hipótesis experimentales |
| 2 | `/speckit.plan` | `specs/00*-*/plan.md` | 6 planes técnicos con experimentación |
| 3 | `/speckit.tasks` | `specs/00*-*/tasks.md` | Tareas con gates de decisión |
| 4 | `/speckit.implement` | `src/` | Código Python + notebooks |
| 4 | `/speckit.implement` | `mlruns/` | Tracking MLflow |
| 5 | `/speckit.analyze` | `specs/00*/final-*.md` | Spec de modelos finales |

---

## 6. Entregas por Módulo

### 6.1 Entregable del Módulo 1: Constitución ML y Biblioteca de Prompts Data (3h)

**Entregables:**

1. `.specify/memory/constitution.md` adaptado para proyectos ML con principios de experimentación reproducible
2. `AGENTS.md` con agentes especializados para proyectos data (@data-dev, @ml-dev, @mlops-dev)
3. Biblioteca de prompts SDD para Data Science (mínimo 15 prompts) incluyendo prompts para baseline experiments, hyperparameter tuning, feature engineering, model evaluation, y SHAP analysis
4. Configuración VS Code para notebooks y debugging ML
5. Templates de notebooks para experimentación estructurada

### 6.2 Entregable del Módulo 2: Specs de Hipótesis y Planes Experimentales (3h)

**Entregables:**

1. `specs/001-data-ingestion/spec.md` con criterios de calidad de datos y requisitos de ingesta
2. `specs/002-feature-engineering/spec.md` con features requeridas e hipótesis sobre importancia
3. `specs/003-hiring-time-model/spec.md` con hipótesis experimentales y métricas objetivo
4. `specs/004-salary-benchmark-model/spec.md` con hipótesis experimentales y métricas objetivo
5. `specs/005-prediction-api/spec.md` con contratos de API y SLAs
6. `specs/006-dashboard/spec.md` con métricas y visualizaciones requeridas
7. Plans correspondientes con planes de experimentación para cada modelo

### 6.3 Entregable del Módulo 3: Implementación con Gates Experimentales (3h)

**Entregables:**

1. `experiments/hiring-time/01_baseline_linear.ipynb` con baseline de regresión lineal
2. `experiments/hiring-time/02_tree_models.ipynb` con Random Forest, XGBoost, LightGBM
3. `experiments/hiring-time/03_final_model.ipynb` con modelo final y SHAP analysis
4. `experiments/salary/01_exploratory_analysis.ipynb` con análisis exploratorio de datos salariales
5. `experiments/salary/02_catboost_baseline.ipynb` con baseline de CatBoost
6. `src/models/hiring_time/train.py` con pipeline de entrenamiento para producción
7. `src/models/salary_benchmark/train.py` con pipeline de entrenamiento para producción
8. `src/api/main.py` con endpoints de predicción funcionales

### 6.4 Entregable del Módulo 4: MLOps, Validación y Documentación (3h)

**Entregables:**

1. Tracking completo en MLflow con experimentos documentados
2. `src/monitoring/drift_detection.py` con sistema de detección de drift
3. Templates de tests para modelos ML incluyendo tests de correctness, performance, y fairness
4. Pipeline CI/CD con quality gates para modelos ML
5. Documentación de API con OpenAPI schema
6. `README.md` completo con guía de ejecución y arquitectura
7. `specs/003-hiring-time-model/final-model-spec.md` con especificación del modelo final
8. `specs/004-salary-benchmark-model/final-model-spec.md` con especificación del modelo final

---

## 7. Resumen de Entregables por Módulo

| Módulo | Entregable Principal | Enfoque SDD | Duración |
|--------|---------------------|-------------|----------|
| **1** | AGENTS.md + Biblioteca de prompts ML + constitution.md | Constitución ML | 3h |
| **2** | 6 specs con hipótesis + 6 plans experimentales | Spec / Plan Experimental | 3h |
| **3** | Notebooks baseline + final + API funcional | Tasks / Implement + Gates | 3h |
| **4** | MLflow tracking + tests + CI/CD + final specs | MLOps + Docs | 3h |

**Artefactos Spec Kit por módulo:**

| Módulo | Comandos Spec Kit | Archivos SDD |
|--------|-------------------|--------------|
| **1** | `/speckit.constitution` | `.specify/memory/constitution.md`, `AGENTS.md` |
| **2** | `/speckit.specify`, `/speckit.plan` | `specs/[feature]/spec.md`, `specs/[feature]/plan.md` |
| **3** | `/speckit.implement`, `/speckit.tasks` | `experiments/`, `src/models/`, `src/api/` |
| **4** | `/speckit.analyze`, `/speckit.validate` | `specs/[feature]/final-*.md`, `mlruns/` |

---

## 8. Stack Tecnológico del Caso Práctico

| Categoría | Tecnología | Versión | Propósito |
|-----------|------------|---------|-----------|
| **Runtime** | Python | 3.11+ | Lenguaje principal |
| **API Framework** | FastAPI | 0.109+ | API REST de predicción |
| **ML Frameworks** | LightGBM | 4.0+ | Hiring Time Model |
| **ML Frameworks** | CatBoost | 0.3+ | Salary Benchmark Model |
| **ML Frameworks** | XGBoost | 2.0+ | Experimentación |
| **Hyperparameter Tuning** | Optuna | 3.5+ | Optimización de hiperparámetros |
| **Experiment Tracking** | MLflow | 2.9+ | Tracking de experimentos |
| **Feature Store** | Feast | 0.40+ | Feature Store |
| **Data Validation** | Great Expectations | 0.18+ | Validación de calidad |
| **Explainability** | SHAP | 0.44+ | Explicabilidad de modelos |
| **Data Processing** | Pandas | 2.1+ | Manipulación de datos |
| **Data Processing** | NumPy | 1.26+ | Operaciones numéricas |
| **Notebooks** | Jupyter | 6.0+ | Experimentación |
| **HTTP Client** | httpx | 0.26+ | Consumo de Portal API |
| **Orchestration** | Schedule | 1.2+ | Jobs programados |
| **Dashboard** | Streamlit | 1.31+ | Visualización |
| **Testing** | pytest | 7.4+ | Framework de tests |
| **Testing** | pytest-cov | 4.1+ | Coverage de tests |
| **CI/CD** | GitHub Actions | - | Automatización |
| **Contenedores** | Docker | - | Containerización |
| **Control de Versiones** | Git LFS | - | Datasets grandes |

---

## 9. Criterios de Éxito del Proyecto

### 9.1 Criterios Técnicos

| Componente | Métrica | Objetivo |
|------------|---------|----------|
| Hiring Time Model | MAE | < 5 días |
| Hiring Time Model | R² | > 0.70 |
| Hiring Time Model | Latencia P99 | < 100ms |
| Salary Benchmark Model | MAPE | < 10% |
| Salary Benchmark Model | Coverage CI | > 80% |
| Sistema | Disponibilidad | 99.5% |
| Sistema | Drift Detection | Alert cuando drift > 5% |

### 9.2 Criterios de Negocio

| Métrica | Objetivo |
|---------|----------|
| Precisión en estimaciones de tiempo | +30% vs. sin sistema |
| Adopción por empresas | 50% en 3 meses |
| Reducción tiempo de screening | 40% |

### 9.3 Criterios de Calidad de Código

| Métrica | Objetivo |
|---------|----------|
| Cobertura de tests unitarios | > 80% |
| Cobertura de tests de integración | > 60% |
| Code smells | 0 high |
| Documentación de APIs | 100% endpoints |

---

## 10. Recursos de Apoyo

### 10.1 Documentación de Referencia

Los siguientes documentos de la base del curso deben consultarse como referencia:

| Archivo | Propósito |
|---------|-----------|
| `base/0.objetivos_curso.md` | Objetivos del curso y herramientas |
| `base/spec-kit.md` | Documentación de GitHub Spec Kit |
| `base/agents_md.md` | Formato y mejores prácticas de AGENTS.md |
| `base/agents_skills_.md` | Documentación de Agent Skills |

### 10.2 Documentos del Proyecto Portal de Empleo

Los siguientes documentos del caso práctico anterior son referencia:

| Archivo | Propósito |
|---------|-----------|
| `labs/01.caso-practico.md` | Caso práctico Portal API |
| `labs/02.guia-implementacion.md` | Guía de implementación .NET |

### 10.3 Links de Interés

| Recurso | Descripción |
|---------|-------------|
| LightGBM Docs | Documentación oficial de LightGBM |
| CatBoost Docs | Documentación oficial de CatBoost |
| MLflow Docs | Documentación oficial de MLflow |
| FastAPI Docs | Documentación oficial de FastAPI |
| SHAP Docs | Documentación de SHAP para explicabilidad |
| Feast Docs | Documentación de Feature Store |

---

## 11. Notas para Instructores

### 11.1 Adaptaciones para el Aula

Este caso práctico está diseñado para un grupo con experiencia previa en Python y conceptos básicos de machine learning. Si el grupo tiene menos experiencia, se recomienda dedicar más tiempo a los módulos 1 y 2, reducir el alcance de modelos a solo Hiring Time, proporcionar notebooks parcialmente completados, y enfatizar más los conceptos de MLOps básicos.

### 11.2 Puntos de Atención

Los puntos críticos donde los estudiantes pueden tener dificultades incluyen la configuración inicial del Feature Store y la conexión con el Portal API, el concepto de gates de decisión y cuándo usarlos, la interpretación de SHAP values y su uso en producción, y la containerización y deployment de modelos.

### 11.3 Evaluación Sugerida

La evaluación del caso práctico puede basarse en rúbrica con los siguientes componentes: calidad de specs y planes (20%), funcionamiento de modelos (30%), calidad de código y tests (25%), MLOps y reproducibilidad (15%), y documentación y presentación (10%).

---

*Caso práctico desarrollado para el curso de Microsoft Copilot en el Entorno de Desarrollo Local, aplicando Spec-Driven Development híbrido para proyectos de machine learning.*
