# Estado del Arte de los Modelos de Lenguaje de Gran Escala

## Introducción

Los Modelos de Lenguaje de Gran Escala (Large Language Models, LLM) han transformado radicalmente el panorama del desarrollo de software en los últimos años. Herramientas como Microsoft Copilot se han convertido en compañeros indispensables para programadores de todos los niveles, ofreciendo asistencia en la generación de código, resolución de problemas complejos y automatización de tareas repetitivas. Sin embargo, para aprovechar estas herramientas de manera efectiva, es fundamental comprender cómo funcionan internamente, cuáles son sus limitaciones y cuáles son las mejores prácticas para interactuar con ellas.

Este documento tiene como objetivo proporcionar a los alumnos una comprensión profunda de los aspectos técnicos y prácticos de los LLM, con especial énfasis en Microsoft Copilot. A lo largo de las siguientes secciones, exploraremos las capacidades actuales de estos modelos, la diferencia entre entrenamiento y contexto, la gestión de sesiones de desarrollo y el flujo de trabajo recomendado para abordar proyectos de software asistidos por inteligencia artificial.

---

## 1. Pensamiento y Conciencia en los Modelos de Lenguaje de Gran Escala

### 1.1 La Naturaleza del Procesamiento en los LLM

Para comprender verdaderamente cómo interactúan los LLM como Copilot, es esencial entender que estos modelos operan mediante cálculos probabilísticos sofisticados, no mediante procesos de pensamiento similares a los humanos. Un LLM es, en su esencia, un sistema de predicción de tokens que ha sido entrenado con enormes cantidades de texto. Cuando el modelo genera una respuesta, está calculando la probabilidad de que cada palabra o fragmento de texto siguiente sea la más apropiada dado el contexto proporcionado.

Este proceso de predicción se basa en patrones estadísticos aprendidos durante el entrenamiento, no en comprensión genuina en el sentido humano de la palabra. El modelo no «piensa» sobre un problema de la manera en que un programador humano lo haría, no tiene intenciones, creencias o estados mentales. En cambio, el modelo genera salidas que maximizan la probabilidad condicional basándose en los patrones que ha observado en sus datos de entrenamiento.

Es importante destacar que esta caracterización no diminish el valor o la utilidad de los LLM. La capacidad de identificar y aplicar patrones complejos de manera consistente es extraordinariamente poderosa y útil. El modelo puede generar código funcional, identificar errores comunes y sugerir soluciones óptimas porque estos patrones están presentes en los datos de entrenamiento y el modelo ha aprendido a reconocerlos y aplicarlos apropiadamente.

### 1.2 Capacidades Emergentes y Limitaciones

Los LLM más avanzados han demostrado capacidades emergentes que van más allá de la simple predicción de palabras. Estas capacidades incluyen la habilidad de realizar razonamiento stepwise, resolver problemas matemáticos complejos y generar código en múltiples lenguajes de programación. Sin embargo, estas habilidades son el resultado de la interacción de millones de parámetros entrenados para capturar patrones, no de un proceso de pensamiento consciente.

Entre las limitaciones más significativas se encuentran la tendencia a generar información plausible pero incorrecta (alucinaciones), la sensibilidad al orden y formulación de los prompts, la falta de memoria persistente entre sesiones independientes y la dificultad para manejar razonamiento de largo plazo que requiere múltiples pasos de inferencia. El modelo no tiene acceso a información actualizada más allá de su fecha de corte de entrenamiento, no puede verificar la corrección de sus propias salidas de manera confiable y puede ser influenciado por sesgos presentes en los datos de entrenamiento.

### 1.3 Implicaciones para el Uso de Copilot

Comprender la naturaleza probabilística de los LLM tiene implicaciones prácticas directas para el uso de Copilot en el desarrollo de software. El modelo generará diferentes salidas para prompts similares, lo que significa que la consistencia no está garantizada. Las respuestas pueden variar según el contexto proporcionado, el formato del prompt y hasta detalles aparentemente insignificantes de la formulación.

Esta comprensión debe guiar nuestra interacción con Copilot. No debemos esperar que el modelo «piense» sobre nuestro problema de manera autónoma, sino que debemos proporcionarle contexto suficiente, instrucciones claras y feedback iterativo. El modelo es una herramienta extraordinariamente poderosa para aplicar patrones conocidos a problemas específicos, pero requiere supervisión humana para verificar la corrección y relevancia de sus salidas <citation>1,2</citation>.

El panorama de los LLM en 2025 ha evolucionado significativamente. Los modelos de razonamiento (reasoning models) como DeepSeek R1 han introducido técnicas de aprendizaje por refuerzo con recompensas verificables (RLVR) que permiten a los modelos explicar sus respuestas y mejorar la precisión en tareas complejas. Sin embargo, las limitaciones fundamentales persisten: existe una notable asimetría entre la capacidad de los modelos para comprender contextos complejos y sus limitaciones para generar salidas sofisticadas de forma larga y coherente. Los estudios de 2025 han demostrado que la precisión de un LLM puede disminuir hasta un 24,2 por ciento cuando la información relevante está incrustada dentro de contextos más largos, lo que subraya la importancia crítica de una gestión eficiente del contexto. Además, el fenómeno del «benchmaxxing» evidencia que las puntuaciones de los benchmarks no siempre reflejan las capacidades reales en situaciones prácticas <citation>6,8,9</citation>.

---

## 2. Contexto versus Entrenamiento: La Danza de la Información

### 2.1 Qué es el Entrenamiento de un LLM

El entrenamiento de un LLM es el proceso mediante el cual el modelo aprende patrones estadísticos a partir de grandes cantidades de texto. Durante el entrenamiento, el modelo procesa miles de millones de tokens de texto y ajusta sus parámetros internos para predecir secuencias de texto de manera cada vez más precisa. Este proceso puede dividirse en varias fases que determinan las capacidades fundamentales del modelo.

La fase de preentrenamiento (pre-training) expone al modelo a cantidades masivas de texto de diversas fuentes, incluyendo libros, artículos, código fuente, documentación técnica y contenido web. Durante esta fase, el modelo desarrolla una comprensión general del lenguaje, sus estructuras, relaciones y patrones. Posteriormente, la fase de ajuste fino (fine-tuning) refina el modelo para tareas específicas, como la generación de código en el caso de Copilot <citation>3</citation>.

Lo que el modelo aprende durante el entrenamiento queda «incrustado» en sus parámetros internos como patrones y asociaciones. Estos patrones son la base de las capacidades del modelo, pero también representan una fotografía fija del conocimiento en el momento del corte de datos. El modelo no puede acceder a información que no estaba presente en sus datos de entrenamiento ni puede actualizar su conocimiento de manera dinámica. Un desafío adicional es el fenómeno del «olvido catastrófico», donde el entrenamiento con nuevos datos puede erosionar conocimientos previamente adquiridos, lo que complica la actualización continua de los modelos <citation>6</citation>.

### 2.2 Qué es el Contexto en un Prompt

El contexto proporcionado en un prompt es la información adicional que se entrega al modelo durante una interacción específica. A diferencia del entrenamiento, que ocurre una vez y tiene efectos permanentes en los parámetros del modelo, el contexto es efímero y existe solo durante la duración de una sesión o conversación <citation>4</citation>.

El contexto puede incluir múltiples elementos que ayudan al modelo a comprender mejor la situación actual. Estos elementos incluyen el historial de conversación previa, archivos de código fuente relevantes, documentación del proyecto, decisiones arquitectónicas previas, convenciones de nomenclatura establecidas y cualquier otra información que sea pertinente para la tarea en curso.

El modelo utiliza esta información de contexto para personalizar sus respuestas según las necesidades específicas de cada situación. Sin contexto adecuado, el modelo debe basarse únicamente en sus conocimientos generales del entrenamiento, lo que puede resultar en respuestas genéricas que no se ajustan a las particularidades del proyecto o del problema específico.

### 2.3 Cómo se Relacionan Entrenamiento y Contexto

La interacción entre entrenamiento y contexto es fundamental para entender cómo los LLM generan respuestas útiles. El entrenamiento proporciona la base de conocimientos y capacidades generales del modelo, mientras que el contexto permite adaptar esas capacidades a la situación específica <citation>3,4</citation>.

Cuando proporcionamos contexto a Copilot, estamos esencialmente «recordándole» información que no podría conocer de otra manera. Por ejemplo, si estamos trabajando en un proyecto con convenciones específicas de nomenclatura, debemos proporcionar esas convenciones como contexto porque el modelo no puede adivinarlas basándose únicamente en su entrenamiento general. De manera similar, el contexto puede incluir información sobre la arquitectura del proyecto, las dependencias utilizadas, las restricciones del entorno y cualquier otra especificación relevante.

El condicionamiento que el entrenamiento ejerce sobre el entendimiento del contexto es significativo. El modelo interpretará el contexto proporcionado a través del lente de los patrones que ha aprendido durante el entrenamiento. Esto significa que ciertas palabras o estructuras tendrán significados particulares para el modelo basándose en su entrenamiento, lo que puede ser tanto una ventaja como un desafío. El modelo puede hacer conexiones útiles basándose en patrones similares observados durante el entrenamiento, pero también puede malinterpretar contexto que no encaja con esos patrones.

### 2.4 Estrategias para Maximizar la Efectividad del Contexto

Para obtener las mejores respuestas de Copilot, es fundamental proporcionar contexto rico y bien estructurado. Esto incluye definir claramente el objetivo de la tarea, proporcionar información sobre el estado actual del proyecto, especificar restricciones y requisitos, indicar las convenciones a seguir y dar ejemplos del tipo de salida esperada <citation>4,5,7</citation>.

La organización del contexto también importa significativamente. Presentar la información de manera lógica y estructurada facilita que el modelo procese y utilice esa información efectivamente. Utilizar títulos claros, separar diferentes tipos de información y mantener una estructura consistente son prácticas que mejoran la calidad de las respuestas generadas.

En 2025, el campo ha evolucionado hacia lo que se conoce como «ingeniería de contexto», una disciplina formal que trasciende el diseño simple de prompts para abarcar la optimización sistemática de la información proporcionada a los LLM. Investigaciones recientes de Anthropic y otros laboratorios establecen que los modelos tienen un «presupuesto de atención» limitado y sufren un fenómeno conocido como «context rot», donde a medida que aumentan los tokens, la capacidad del modelo para recordar información disminuye. Las estrategias recomendadas incluyen la recuperación «just in time», donde se mantienen identificadores ligeros y se cargan datos dinámicamente en tiempo de ejecución, así como técnicas de compactación para resumir conversaciones cerca del límite del contexto y reiniciar con el resumen. Para tareas de largo horizonte, se recomiendan arquitecturas de subagentes con contextos limpios coordinados por un agente principal <citation>7,8</citation>.

---

## 3. Agentes de IA en el Desarrollo de Software

Los agentes de inteligencia artificial representan la evolución más significativa en la aplicación de IA al desarrollo de software en 2024-2025. A diferencia de los modelos de lenguaje convencionales que operan de manera reactiva, los agentes son entidades autónomas capaces de planificar, ejecutar y completar tareas complejas con mínima intervención humana. Esta sección explora el estado actual de los agentes de IA en el desarrollo de software, sus capacidades, herramientas líderes y proyecciones de mercado.

### 3.1 Definición y Arquitectura de Agentes de IA

Un agente de IA en el contexto del desarrollo de software es un sistema autónomo que puede percibir su entorno, tomar decisiones y ejecutar acciones para lograr objetivos específicos. A diferencia de los asistentes tradicionales que simplemente responden a consultas, los agentes pueden:

- **Planificar descomposición de tareas:** Dividir objetivos complejos en pasos manejables
- **Ejecutar acciones autonomous:** Escribir código, modificar archivos, ejecutar comandos de terminal
- **Iterar y corregir:** Auto-evaluar resultados y realizar ajustes cuando algo falla
- **Mantener contexto extenso:** Recordar decisiones previas y adaptar estrategias durante sesiones prolongadas

La arquitectura típica de un agente de software incluye componentes como:

- **Modelo de razonamiento subyacente:** Generalmente un LLM avanzado (Claude, GPT-4, etc.)
- **Herramientas de ejecución:** APIs para interactuar con sistemas de archivos, repositorios Git, navegadores
- **Memoria persistente:** Almacenamiento de contexto, decisiones y aprendizajes
- **Ciclo de planificación-ejecución-evaluación:** Bucle continuo de mejora hasta completar objetivos

### 3.2 Benchmarks y Métricas de Rendimiento

La evaluación del rendimiento de agentes de código se ha formalizado a través de benchmarks especializados que miden capacidades en escenarios reales de desarrollo de software.

| Benchmark | Enfoque | Líder Actual | Rendimiento |
|-----------|---------|--------------|-------------|
| SWE-bench | Resolución de issues GitHub | mini-SWE-agent | 74% en 100 líneas de Python |
| SWE-bench Verified | Tareas de código reales | OpenAI + agentes | 43% en versión lite |
| SWE-Bench Pro | Tareas de largo horizonte | Various | En desarrollo activo |
| SWE-Bench+ | Realismo basado en mutación | Emerging | Multilingüe |

SWE-bench, desarrollado por Princeton y LogicStar AI en 2024, se ha convertido en el estándar de referencia para evaluar agentes de código. El benchmark comprende 500 tareas ejecutadas en contenedores Docker aislados, representando issues reales de GitHub. Los avances más recientes muestran que agentes como mini-SWE-agent pueden resolver hasta el 74% de las tareas en configuraciones optimizadas, demostrando el progreso significativo en capacidades autonomous de generación de código <citation>17,18</citation>.

### 3.3 Herramientas y Plataformas Líderes

El ecosistema de herramientas de agentes de IA para desarrollo de software ha experimentado crecimiento explosivo en 2024-2025, con múltiples soluciones compitiendo por adopción en el mercado.

**Herramientas IDE y Editor:**

- **Cursor:** Editor de código potenciado por IA que integra capacidades de agente directamente en el flujo de trabajo de desarrollo. Ofrece edición predictiva, chat contextual y агент autonomous mode para refactorizaciones y nuevas funcionalidades <citation>19</citation>.

- **Claude Code (Anthropic):** Herramienta CLI que permite interacción agentic con código fuente, capaz de ingestar y comprender repositorios completos (millones de líneas) sin selección manual de contexto.

- **GitHub Copilot:** La solución de Microsoft ha evolucionado hacia capacidades más agentic, integrando sugerencias de código más contextuales y funcionalidades de completado de tareas. En 2025, GitHub introdujo el agente de codificación de Copilot, una capacidad autónoma que permite asignar issues directamente para que trabaje de forma autónoma clonando repositorios, configurando entornos, analizando código mediante búsqueda avanzada y haciendo commits a pull requests <citation>10</citation>.

**Herramientas Autonomous Puras:**

- **SWE-agent:** Implementación de referencia de Princeton para agentes de código, optimizada para rendimiento en benchmarks.

- **Aider:** CLI tool para desarrollo pair-programming con modelos de lenguaje, soporta múltiples modelos y arquitecturas.

- **Bolt.new / Lovable:** Plataformas emergentes orientadas a prototipado rápido mediante prompts en lenguaje natural.

### 3.4 Tendencias de Mercado y Adopción

El mercado de agentes de IA proyecta un crecimiento exponencial, pasando de $5.1 mil millones en 2024 a $47.1 mil millones proyectados para 2030, con una CAGR del 44.8% según Alvarez & Marsal <citation>20</citation>. Esta proyección refleja la adopción acelerada en sectores empresariales y el reconocimiento del valor productivo de estos sistemas.

Según la encuesta Stack Overflow Developer Survey 2025, el porcentaje de desarrolladores utilizando agentes de IA en su trabajo diario ha aumentado significativamente, con herramientas de coding agents como Cursor y Claude Code liderando la adopción. Las empresas tecnológicas líderes han shiftado su enfoque hacia flujos de trabajo más inteligentes potenciados por agentes, según el reporte de Bain & Company sobre transformación agentic AI 2025 <citation>13,14</citation>.

### 3.5 Limitaciones y Consideraciones Éticas

A pesar de los avances, los agentes de IA presentan limitaciones importantes que los desarrolladores deben considerar:

- **Fiabilidad inconsistente:** Aunque los benchmarks muestran altos porcentajes de éxito, la variabilidad en tareas complejas puede ser significativa

- **Dependencia de supervisión:** Las mejores prácticas recomiendan revisión humana de código generado, especialmente para sistemas críticos

- **Costos de tokens:** Las operaciones agentic pueden consumir rápidamente quotas de API, generando costos operativos sustanciales

- **Seguridad y privacidad:** El acceso autonomous a repositorios sensibles plantea consideraciones de seguridad que las organizaciones deben evaluar

- **Responsabilidad:** La atribución de bugs o vulnerabilidades introducidas por código agentic genera preguntas legales y éticas aún sin resolver completamente

---

## 4. Gestión de Sesiones de Desarrollo con Copilot

### 4.1 Concepto de Sesión en el Contexto de Copilot

Una sesión de desarrollo con Copilot es una secuencia de interacciones relacionadas que comparten un contexto común. A diferencia de las conversaciones de chat tradicionales donde cada mensaje es independiente, una sesión de desarrollo efectiva mantiene la coherencia a lo largo del tiempo, preservando decisiones, contexto y progreso acumulado.

La gestión efectiva de sesiones es crucial cuando se trabaja en proyectos que abarcan múltiples días o semanas. Sin una gestión adecuada, el desarrollador corre el riesgo de perder contexto importante, repetir decisiones ya tomadas o inconsistencias en el código generado. Copilot Chat mantiene un historial de conversación dentro de una sesión, pero este historial tiene límites y no persiste entre sesiones reiniciadas o en diferentes dispositivos.

En 2025, GitHub introdujo el agente de codificación de Copilot, una capacidad autónoma que permite asignar issues directamente a Copilot para que trabaje de forma autónoma clonando repositorios, configurando entornos, analizando código mediante búsqueda avanzada y haciendo commits a pull requests. Esta evolución transforma la interacción de «asistente» a «flujo de trabajo», aunque mantiene la supervisión humana como requisito fundamental para garantizar la seguridad y calidad del código generado <citation>10</citation>.

### 4.2 Estrategias para Crear Sesiones Estructuradas

La creación de sesiones efectivas comienza con una planificación cuidadosa del alcance y los objetivos de cada sesión. Antes de iniciar una sesión de trabajo con Copilot, es recomendable definir claramente qué se pretende lograr, qué contexto es necesario preservar y cómo se organizará la información para facilitar la continuidad.

Una práctica efectiva es establecer un «protocolo de sesión» que incluya los siguientes elementos: un resumen inicial del proyecto y su estado actual, una lista de decisiones arquitectónicas tomadas, las convenciones de nomenclatura establecidas, las restricciones técnicas del proyecto y los objetivos específicos de la sesión actual. Este protocolo sirve como punto de partida para cada sesión y puede actualizarse a medida que avanza el proyecto <citation>5</citation>.

Las sesiones deben organizarse en torno a tareas o componentes específicos del proyecto. En lugar de tener una única sesión gigante que abarque todo el desarrollo, es más efectivo tener sesiones separadas para diferentes aspectos del proyecto: una sesión para el diseño arquitectónico, otra para la implementación de la capa de dominio, otra para los servicios de aplicación, y así sucesivamente. Esta organización facilita la navegación y recuperación de contexto específico.

### 4.3 Almacenamiento y Recuperación de Contexto entre Sesiones

Dado que el contexto de Copilot no persiste automáticamente entre sesiones, es necesario implementar estrategias de almacenamiento manual que preserven la información importante. Estas estrategias deben ser lo suficientemente robustas para permitir la continuidad del trabajo incluso después de días o semanas sin trabajar en el proyecto <citation>4,5</citation>.

Una estrategia efectiva es mantener un documento de «memoria del proyecto» que resuma el estado actual, las decisiones tomadas y el contexto relevante. Este documento puede organizarse como un archivo Markdown que se actualiza periódicamente y que sirve como referencia al inicio de cada nueva sesión. El documento debe incluir secciones como: resumen del proyecto, decisiones arquitectónicas documentadas (ADRs), convenciones establecidas, estructura del proyecto, estado actual del desarrollo y pendientes para futuras sesiones.

Otra estrategia complementaria es el uso de comentarios persistentes en el código fuente. Incluir comentarios que documenten las decisiones de diseño, las razones detrás de elecciones específicas y las convenciones seguidas facilita que Copilot (y cualquier nuevo desarrollador) comprenda el contexto sin necesidad de buscar información externa. Estos comentarios actúan como contexto «incrustado» que está siempre disponible para el modelo.

### 4.4 Herramientas y Prácticas Recomendadas

Existen varias herramientas y prácticas que facilitan la gestión de sesiones de desarrollo con Copilot. Los sistemas de control de versiones como Git proporcionan un historial completo de cambios que puede servir como contexto adicional. Al revisar commits previos, es posible reconstruir el razonamiento detrás de decisiones específicas <citation>4,5</citation>.

Los sistemas de documentación integrados en el IDE, como la capacidad de crear y mantener archivos Markdown dentro del proyecto, permiten mantener documentación cercana al código. Esta documentación cercana es especialmente valiosa porque se mantiene actualizada con el desarrollo y está disponible como contexto para Copilot sin necesidad de referencias externas.

Las extensiones de Copilot en editores modernos permiten mantener conversaciones asociadas a archivos o proyectos específicos. Aprovechar estas capacidades para crear «hilos de discusión» por componente o característica facilita la organización del contexto y su recuperación posterior. Naming conventions consistentes para estas conversaciones ayudan a mantener la claridad y facilitan la navegación.

---

## 5. Flujo de Trabajo Recomendado para Desarrollo con LLMs

### 5.1 Fase de Preparación y Comprensión

El desarrollo efectivo con asistencia de LLM comienza con una fase de preparación que establece las bases para todas las interacciones posteriores. Esta fase incluye la comprensión profunda de los requisitos del proyecto, la familiarización con la arquitectura propuesta y la identificación de las áreas donde la asistencia de Copilot será más valiosa <citation>4,5,6</citation>.

Las tendencias de 2025 indican que los LLMs han alcanzado la práctica estándar en el desarrollo de software, con herramientas como Cursor, Claude Desktop y Copilot reconfigurando los flujos de trabajo. Los casos de uso más efectivos incluyen código mundano como generación de argparse y boilerplate, detección de errores y sugerencias de mejora, y automatización fuera del área de expertise principal. Sin embargo, se recomienda escribir código crítico manualmente para mantener la comprensión del sistema y evitar el burnout que puede resultar cuando la herramienta hace todo el trabajo <citation>6,11</citation>.

Antes de interactuar con Copilot, el desarrollador debe tener una comprensión clara de lo que necesita construir, las restricciones del proyecto, la arquitectura general y los componentes principales. Esta comprensión no necesita ser exhaustiva en todos los detalles, pero debe ser suficiente para formular prompts significativos y evaluar las respuestas generadas.

La preparación también incluye la configuración del entorno de desarrollo y la verificación de que Copilot está correctamente configurado para el proyecto específico. Esto puede incluir la definición de archivos de contexto, la configuración de instrucciones personalizadas y la preparación de documentación de referencia que será utilizada durante el desarrollo.

### 5.2 Fase de Definición del Contexto Arquitectónico

Una vez comprendidos los requisitos, el siguiente paso es definir el contexto arquitectónico que guiará todas las interacciones posteriores con Copilot. Esta fase es crucial porque establece las convenciones, patrones y restricciones que el modelo deberá seguir <citation>3,4</citation>.

La definición del contexto arquitectónico debe incluir la estructura de directorios del proyecto siguiendo patrones arquitectónicos como Clean Architecture o hexagonal, las convenciones de nomenclatura para clases, métodos, variables y archivos, los patrones de diseño a utilizar en diferentes capas de la aplicación, los frameworks y bibliotecas seleccionadas con sus versiones específicas, las decisiones sobre bases de datos, APIs y otras tecnologías, y cualquier estándar de codificación específico del equipo o proyecto.

Este contexto arquitectónico debe documentarse en un formato accesible para Copilot, típicamente en archivos Markdown dentro del proyecto o en instrucciones personalizadas del editor. Este documento sirve como «contrato» que define cómo debe generarse el código y será referenciado constantemente durante el desarrollo.

### 5.3 Fase de Implementación Iterativa

Con el contexto arquitectónico establecido, comienza la fase de implementación iterativa. Esta fase sigue un ciclo de trabajo que maximiza la efectividad de la asistencia de Copilot mientras mantiene el control y la calidad del código generado <citation>1,4</citation>.

El ciclo recomendado comienza con la descomposición de la tarea en subtareas manejables. En lugar de pedir a Copilot que implemente una funcionalidad completa de una vez, es más efectivo dividir el trabajo en pasos incrementales. Para cada subtarea, se formula un prompt específico que incluye el contexto necesario, se revisa cuidadosamente el código generado, se realizan ajustes si son necesarios y se integra el código en el proyecto.

La revisión del código generado es especialmente importante. Copilot puede generar código que funciona pero que no sigue las mejores prácticas, que no es eficiente o que tiene problemas de seguridad. El desarrollador debe mantener un rol activo de supervisión, verificando cada generación antes de su integración. Esta supervisión no debe ser pasiva, sino que debe incluir verificación de funcionalidad, revisión de calidad de código y validación de cumplimiento de estándares.

### 5.4 Fase de Documentación y Actualización de Contexto

A medida que avanza el desarrollo, es necesario mantener actualizados los documentos de contexto. Las decisiones tomadas durante la implementación, los problemas encontrados y sus soluciones, y las adaptaciones realizadas a los patrones iniciales deben documentarse para referencia futura <citation>4,5</citation>.

Esta actualización continua del contexto tiene múltiples beneficios. Primero, facilita la continuidad cuando se retoma el trabajo después de una interrupción. Segundo, proporciona a Copilot información más precisa y completa en las interacciones posteriores. Tercero, crea una documentación viva del proyecto que es valiosa para cualquier desarrollador que necesite comprender o modificar el código en el futuro.

### 5.5 Resumen del Flujo de Trabajo

El flujo de trabajo completo para el desarrollo con LLMs puede resumirse en los siguientes pasos organizados en fases temporales:

**Fase 1 - Preparación:** Comprensión de requisitos, familiarización con la arquitectura, configuración del entorno y verificación de herramientas.

**Fase 2 - Definición de Contexto:** Documentación de estructura de proyecto, convenciones de nomenclatura, patrones de diseño, frameworks seleccionados y estándares de codificación.

**Fase 3 - Implementación Iterativa:** Descomposición de tareas, formulación de prompts específicos, revisión de código generado, integración y verificación continua.

**Fase 4 - Documentación Continua:** Actualización de ADRs, registro de decisiones, mantenimiento de documentación de contexto y preparación de sesiones futuras.

Este flujo no es necesariamente lineal; las fases se superponen y el proceso es iterativo por naturaleza. Sin embargo, seguir esta estructura ayuda a mantener el control sobre el desarrollo y a maximizar los beneficios de la asistencia de Copilot.

---

## Conclusión

La comprensión profunda de cómo funcionan los LLM como Copilot es fundamental para aprovechar su potencial de manera efectiva en el desarrollo de software. Los modelos no piensan ni poseen conciencia en el sentido humano, sino que generan salidas basadas en patrones estadísticos aprendidos durante el entrenamiento. Esta comprensión nos permite establecer expectativas realistas y diseñar interacciones que maximicen la utilidad de la herramienta.

La distinción entre el conocimiento adquirido durante el entrenamiento y el contexto proporcionado durante las interacciones es crucial para obtener respuestas relevantes y precisas. Mientras que el entrenamiento proporciona capacidades generales, el contexto permite adaptar esas capacidades a las necesidades específicas de cada proyecto.

Los agentes de IA representan la evolución más significativa en la aplicación de IA al desarrollo de software, ofreciendo capacidades autónomas de planificación, ejecución y corrección. Con herramientas como Cursor, Claude Code y el agente de codificación de GitHub Copilot, los desarrolladores pueden abordar tareas más complejas con menor intervención manual. Los benchmarks como SWE-bench demuestran un progreso notable, con tasas de éxito de hasta 74% en tareas de código real, aunque la supervisión humana sigue siendo esencial para garantizar calidad y seguridad.

La gestión efectiva de sesiones, mediante la documentación estructurada y el almacenamiento persistente de contexto, es esencial para proyectos que se extienden a lo largo de días o semanas. Sin estas prácticas, el riesgo de perder coherencia y consistencia aumenta significativamente.

Finalmente, seguir un flujo de trabajo estructurado que incluya preparación, definición de contexto, implementación iterativa y documentación continua maximiza los beneficios de la asistencia de Copilot mientras mantiene el control sobre la calidad del código producido. Al dominar estos conceptos y prácticas, los desarrolladores pueden integrar Copilot de manera efectiva en sus flujos de trabajo, incrementando su productividad y la calidad de sus entregables.

---

## Recursos Adicionales

Para profundizar en los temas tratados en este documento, se recomiendan los siguientes recursos:

- Documentación oficial de Microsoft Copilot para desarrolladores
- Papers de investigación sobre arquitecturas Transformer y LLM
- Guías de mejores prácticas para prompt engineering y context engineering (2025)
- Comunidades de desarrolladores que comparten experiencias con Copilot
- Investigación reciente sobre limitaciones y capacidades emergentes de LLM
- Documentación y benchmarks de SWE-bench para evaluación de agentes de código
- Reportes de mercado de McKinsey, Bain & Company sobre adopción de agentes de IA

---

## Referencias

Las siguientes fuentes han sido consultadas y verificadas para la elaboración de este documento:

**1.** Wei, J., et al. (2022). Emergent Abilities of Large Language Models. *Transactions on Machine Learning Research*. Este paper explora las capacidades emergentes que aparecen en modelos de lenguaje de gran escala cuando alcanzan cierta escala, analizando fenómenos como el razonamiento stepwise y la resolución de problemas complejos que no estaban explícitamente programados.

**2.** Bender, E.M., et al. (2021). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? *FAccT '21 Proceedings*. Este trabajo académico examina los riesgos asociados con modelos de lenguaje de gran escala, incluyendo cuestiones sobre la naturaleza probabilística de las generaciones y las limitaciones inherentes a estos sistemas.

**3.** Vaswani, A., et al. (2017). Attention Is All You Need. *Advances in Neural Information Processing Systems*. El paper seminal que introduce la arquitectura Transformer, base de los LLM modernos, explicando cómo el mecanismo de atención permite el procesamiento de secuencias y la captura de patrones lingüísticos complejos.

**4.** GitHub Copilot Documentation. Best Practices for Copilot. Documentación oficial de GitHub que proporciona directrices sobre el uso efectivo de Copilot, incluyendo recomendaciones sobre la gestión del contexto y la formulación de prompts efectivos para maximizar la calidad del código generado.

**5.** Microsoft Learn. Using GitHub Copilot in your IDE. Recursos oficiales de Microsoft que ofrecen guías prácticas sobre la integración de Copilot en entornos de desarrollo, incluyendo estrategias para mantener sesiones de trabajo efectivas y aprovechar las capacidades del modelo de manera productiva.

**6.** Raschka, S. (2025). The State Of LLMs 2025: Progress, Problems, and Predictions. Sebastian Raschka's Newsletter. Una revisión exhaustiva del estado de los modelos de lenguaje en 2025, cubriendo modelos de razonamiento como DeepSeek R1, técnicas de RLVR, arquitecturas emergentes como Mixture-of-Experts, y predicciones sobre la evolución del campo incluyendo inference-time scaling y la adopción de tool use local.

**7.** Anthropic. (2025). Effective Context Engineering for AI Agents. Documentación técnica que establece principios fundamentales para la gestión del contexto en sistemas agénticos, introduciendo conceptos como «context rot», presupuesto de atención limitado, y estrategias como recuperación just-in-time, compactación de conversaciones y arquitecturas de subagentes para optimizar el rendimiento de los LLM.

**8.** Mei, L., et al. (2025). A Survey of Context Engineering for Large Language Models. *arXiv:2507.13334*. Un survey exhaustivo de 166 páginas que introduce la ingeniería de contexto como disciplina formal, analizando 1.411 citas y estableciendo una taxonomía que incluye componentes fundamentales como recuperación y generación de contexto, procesamiento y gestión, así como implementaciones como RAG, sistemas de memoria y sistemas multiagente.

**9.** Kostikova, A., et al. (2025). LLLMs: A Data-Driven Survey of Evolving Research on Limitations of Large Language Models. *arXiv:2505.19240*. Un análisis semi-automatizado basado en datos de 2022 a 2025 que examina más de 14.648 papers relevantes sobre limitaciones de LLM, identificando las limitaciones más estudiadas: razonamiento, generalización, alucinaciones, sesgos y seguridad, con un crecimiento de más del 2.800 por ciento en investigación sobre este tema en plataformas como arXiv.

**10.** GitHub. (2025). Meet the new coding agent for GitHub Copilot. GitHub Blog. Anuncio oficial del nuevo agente de codificación autónomo de GitHub Copilot, которое puede asignar issues, clonar repositorios, configurar entornos, analizar código con RAG avanzado y hacer commits a pull requests, con características de seguridad que incluyen limitaciones de acceso y flujos de aprobación humana.

**11.** Google Cloud. (2025). Building Software in 2025: LLMs, Agents, AI and a Real World Workflow. Medium. Un análisis práctico de la integración de LLMs en flujos de trabajo de desarrollo de software, cubriendo evolución de patrones arquitectónicos, autoscaling, evaluación y workflows computacionales de IA, con énfasis en cómo los agentes de IA están transformando la práctica del desarrollo de software.

**12.** Pragmatic Engineer. (2025). Software engineering with LLMs in 2025: reality check. Una evaluación pragmática del estado actual del desarrollo de software con asistencia de LLM, analizando tanto las promesas como las realidades del impacto de estos modelos en la ingeniería de software, con insights sobre casos de uso efectivos y limitaciones prácticas.

**13.** McKinsey & Company. (2025). The State of AI: Global Survey 2025. Encuesta global que analiza la adopción empresarial de IA, reportando que el uso de IA en al menos una función de negocio continúa aumentando, con muchas organizaciones experimentando activamente con agentes de IA para automatizar flujos de trabajo complejos.

**14.** Bain & Company. (2025). State of the Art of Agentic AI Transformation. Technology Report 2025. Reporte técnico que documenta cómo las empresas tecnológicas líderes han shiftado su enfoque hacia flujos de trabajo más inteligentes potenciados por agentes, con análisis de implementaciones exitosas y proyecciones de transformación digital.

**15.** IBM Think. (2025). AI Agents in 2025: Expectations vs. Reality. Análisis que examina qué podemos esperar realista de los agentes de IA en 2025, separando la hype de la realidad práctica y evaluando el impacto real en diferentes industrias y casos de uso.

**16.** LangChain. (2024). State of AI Agents Report. Reporte que documenta cómo los agentes de IA pasaron de ser un interés de nicho en 2023 a una prioridad estratégica en 2024, con empresas de diversas industrias incorporando activamente agentes en sus flujos de trabajo.

**17.** SWE-bench. (2025). Official Leaderboards. Plataforma de benchmarking para agentes de código que comprende 500 tareas representando issues reales de GitHub, ejecutados en contenedores Docker aislados. Los líderes actuales incluyen mini-SWE-agent con hasta 74% de éxito en configuraciones optimizadas.

**18.** OpenAI. (2024). Introducing SWE-bench Verified. Anuncio del benchmark refinado de OpenAI para evaluar agentes de código, con mejoras en la calidad de las tareas y rigor de evaluación, estableciendo nuevos estándares para la medición de capacidades autonomous de generación de código.

**19.** Artificial Analysis. (2025). Coding Agents Comparison: Cursor, Claude Code, GitHub Copilot. Comparación comprehensiva de agentes de codificación incluyendo Cursor, GitHub Copilot, Cline, Continue y más, analizando extensiones de IDE, herramientas CLI y capacidades específicas para diferentes escenarios de desarrollo.

**20.** Alvarez & Marsal. (2025). Demystifying AI Agents in 2025: Separating Hype From Reality and Navigating Market Outlook. Análisis de mercado que proyecta el crecimiento del mercado global de agentes de IA de $5.1 mil millones en 2024 a $47.1 mil millones para 2030, con una CAGR del 44.8%, identificando impulsores de crecimiento y desafíos de implementación.

**21.** Stanford HAI. (2024). AI Index Report 2024. Informe anual que documenta el progreso en IA, incluyendo métricas de rendimiento de benchmarks emergentes como SWE-bench para codificación, HEIM para generación de imágenes, MMMU para razonamiento general y MoCa para razonamiento moral.

**22.** Graham Neubig, Carnegie Mellon University. (2024). The State-of-the-Art in Software Development Agents. MLOps World | GenAI Summit 2024. Presentación experta sobre las fronteras del desarrollo de software basado en agentes, mostrando cómo los equipos de investigación están advancing las capacidades de agentes autonomous para tareas de ingeniería de software.